#!/usr/bin/env python2
import sys, os, subprocess

# Anything not on this dictionary will be converted as-is.
token_map = {
    "SKIPS": "Ignore",
    "BLOCK": "Block",
    "SCOPE": "Scope",
    "LABEL": "Label",
    "ARRAY": "Array",
    "COMMAND": "Command",
    "OP_LE": "Lesser",
    "OP_LEQ": "LesserEqual",
    "OP_GE": "Greater",
    "OP_GEQ": "GreaterEqual",
    "OP_EQ": "Equal",
    "OP_ADD": "Plus",
    "OP_SUB": "Minus",
    "OP_MUL": "Times",
    "OP_DIV": "Divide",
    "OP_MOD": "Module",
    "OP_TIMED_ADD": "TimedPlus",
    "OP_TIMED_SUB": "TimedMinus",
    "OP_CAST": "Cast",
    "OP_SHL": "LeftShift",
    "OP_SHR": "RightShift",
    "OP_AND": "BitAND",
    "OP_OR":  "BitOR",
    "OP_XOR": "BitXOR",
    "OP_INC": "Increment",
    "OP_DEC": "Decrement",
    ##
    "IDENTIFIER": "Identifier",
    "FILENAME": "Filename",
    "INTEGER": "Integer",
    "FLOAT": "Float",
    "STRING": "String",
};

# Any token name on this list won't be passed to our C++ enum
ignore_map = [
    "COMMENT",
    "DEC_DIGIT",
    "DEC_LITERAL",
    "ESC_SEQ",
    "EXPONENT",
    "FLOAT_LITERAL",
    "HEX_DIGIT",
    "HEX_LITERAL",
    "OCTAL_ESC",
    "OCT_DIGIT",
    "OCT_LITERAL",
    "UNICODE_ESC",
    "WS",
];

def main():
    try:
        os.environ['CLASSPATH'] = os.environ.get('CLASSPATH', "") + ';' + '../../deps/antlr-3.5.2.jar'
        output = subprocess.check_output(["java", "org.antlr.Tool", "gta3script.g", "-o", "autogen"], stderr=subprocess.STDOUT)  
    except subprocess.CalledProcessError as e:
        print(e.output)
        print("\nFailed to generate grammar.")
        sys.exit(1)
    else:
        print(output)
        print("\nPlease ignore warning(24)!!!!!!")

        tokens = []

        for line in open("autogen/gta3script.tokens", "r"):
            global token_map
            token_info = line.strip().split('=')
            token_name = token_info[0]
            token_id = token_info[1]

            if not token_name.startswith("T__") and len(token_name) > 1 and \
               not token_name in ignore_map and token_name[0] != "'":
                t = (token_map.get(token_name, token_name), token_id)
                tokens.append(t)

        with open("autogen/gta3scriptsTokens.hpp", "w") as f:
            f.write("#pragma once\n")
            f.write("// Autogenerated by autogen.py, don't modify manually!\n")
            f.write("enum class Token\n")
            f.write("{\n")
            for k,v in tokens:
                f.write('\t' + k + " = " + v + ',\n')
            f.write("};")

        print("\nGrammar generated successfully.")

if __name__ == "__main__":
    main()
